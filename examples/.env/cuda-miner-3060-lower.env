# NVIDIA RTX 3060 (SM 86) — CUDA G2 auto-tuned lower profile (mixed-load systems)
# This profile enables the G2 kernel with auto-tuned per-batch iterations.
# Do NOT set MINER_CUDA_DESIRED_ITERS; the host will auto-tune to cover each window per batch.
# Use this on systems that have other GPU workloads or a display attached.

# Kernel mode and image
MINER_CUDA_MODE=g2
MINER_CUDA_IMAGE=ptx

# Launch geometry (moderate to reduce contention with other GPU loads)
# - THREADS: maximum threads the launcher may use; actual active threads are tuned per batch
# - BLOCK_DIM: CUDA block size (256 is a good default on Ampere)
MINER_CUDA_THREADS=3072
MINER_CUDA_BLOCK_DIM=256

# Per-thread iteration budget (upper bound used by autotuner)
# The autotuner will pick desired_iters <= MINER_CUDA_ITERS to cover the current window.
MINER_CUDA_ITERS=8192

# Batches per window: a few batches to reduce kernel dwell and improve responsiveness
MINER_CUDA_BATCHES=4

# Enable device sampler (captures y/H/target/threshold for parity on first (tid=0,j=0))
MINER_CUDA_SAMPLER=1

# Host-side verification: light sampling to detect missed winners without heavy CPU cost
MINER_CUDA_VERIFY=1024

# Optional: force a device-side early-exit at (tid=0,j=0) to validate GPU->CPU signaling.
# Leave commented/disabled for normal operation.
# MINER_CUDA_FORCE_WIN=1

# Logging (info level to limit noise on shared systems)
RUST_LOG=miner=info

# Tips for shared systems:
# - If you notice UI stutter or other workloads lagging, try:
#     - Lowering MINER_CUDA_THREADS (e.g., 2048), and/or
#     - Increasing MINER_CUDA_BATCHES (e.g., 6–8) to shorten individual kernel dwell.
# - Keep MINER_CUDA_SAMPLER=1 while validating parity; disable to minimize overhead later.
